{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d29d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:12.256443Z",
     "iopub.status.busy": "2023-11-15T13:25:12.256150Z",
     "iopub.status.idle": "2023-11-15T13:25:40.145913Z",
     "shell.execute_reply": "2023-11-15T13:25:40.144991Z"
    },
    "papermill": {
     "duration": 27.899737,
     "end_time": "2023-11-15T13:25:40.148204",
     "exception": false,
     "start_time": "2023-11-15T13:25:12.248467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\r\n",
      "  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\r\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\r\n",
      "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=56df4fb0f14147341980d5bf9dcec04073f43960a1ad6259615e6c8103c583a5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=e2fb0dccab4983c2f03daa2d5979afa7dbb6b23a61bef287b6de456062fbee43\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.10\r\n",
      "    Uninstalling timm-0.9.10:\r\n",
      "      Successfully uninstalled timm-0.9.10\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchinfo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "# from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "!pip install segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839742be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:40.168009Z",
     "iopub.status.busy": "2023-11-15T13:25:40.167711Z",
     "iopub.status.idle": "2023-11-15T13:25:41.758054Z",
     "shell.execute_reply": "2023-11-15T13:25:41.757060Z"
    },
    "papermill": {
     "duration": 1.603209,
     "end_time": "2023-11-15T13:25:41.760918",
     "exception": false,
     "start_time": "2023-11-15T13:25:40.157709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 215MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet50\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57e6815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:41.786016Z",
     "iopub.status.busy": "2023-11-15T13:25:41.785715Z",
     "iopub.status.idle": "2023-11-15T13:25:41.800507Z",
     "shell.execute_reply": "2023-11-15T13:25:41.799685Z"
    },
    "papermill": {
     "duration": 0.02776,
     "end_time": "2023-11-15T13:25:41.802441",
     "exception": false,
     "start_time": "2023-11-15T13:25:41.774681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageSegmentationDataset(Dataset):\n",
    "    \"\"\"Dataset for loading and transforming image segmentation data.\"\"\"\n",
    "    def __init__(self, images_folder, masks_folder, target_size=None, augmentations=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.masks_folder = masks_folder\n",
    "        self.target_size = target_size\n",
    "        self.augmentations = augmentations\n",
    "        self.file_names = os.listdir(self.images_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def load_segmentation_mask(self, path_to_mask):\n",
    "        segmentation_image = cv2.imread(path_to_mask)\n",
    "        segmentation_image = cv2.resize(segmentation_image, self.target_size)\n",
    "        segmentation_image = cv2.cvtColor(segmentation_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        red_lower_bound = np.array([0, 100, 20])\n",
    "        red_upper_bound = np.array([10, 255, 255])\n",
    "        lower_red_mask = cv2.inRange(segmentation_image, red_lower_bound, red_upper_bound)\n",
    "        upper_red_mask = cv2.inRange(segmentation_image, np.array([160, 100, 20]), np.array([179, 255, 255]))\n",
    "        \n",
    "        combined_red_mask = lower_red_mask + upper_red_mask\n",
    "        combined_red_mask[combined_red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(segmentation_image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        complete_mask = cv2.bitwise_or(combined_red_mask, green_mask)\n",
    "        complete_mask = np.expand_dims(complete_mask, axis=-1)\n",
    "        complete_mask = complete_mask.astype(np.uint8)\n",
    "        return complete_mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_to_image = os.path.join(self.images_folder, self.file_names[index])\n",
    "        path_to_mask = os.path.join(self.masks_folder, self.file_names[index])\n",
    "        input_image = cv2.imread(path_to_image)\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "        segmentation_mask = self.load_segmentation_mask(path_to_mask)\n",
    "        input_image = cv2.resize(input_image, self.target_size)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=input_image)\n",
    "            input_image = augmented['image']\n",
    "        \n",
    "        segmentation_mask = torch.tensor(segmentation_mask, dtype=torch.float32)\n",
    "        segmentation_mask = segmentation_mask.permute(2, 0, 1)\n",
    "\n",
    "        return input_image, segmentation_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0d7f1",
   "metadata": {
    "papermill": {
     "duration": 0.009322,
     "end_time": "2023-11-15T13:25:41.821071",
     "exception": false,
     "start_time": "2023-11-15T13:25:41.811749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1b692c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:41.843070Z",
     "iopub.status.busy": "2023-11-15T13:25:41.842800Z",
     "iopub.status.idle": "2023-11-15T13:25:42.587818Z",
     "shell.execute_reply": "2023-11-15T13:25:42.586944Z"
    },
    "papermill": {
     "duration": 0.758614,
     "end_time": "2023-11-15T13:25:42.590179",
     "exception": false,
     "start_time": "2023-11-15T13:25:41.831565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac21936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:42.610528Z",
     "iopub.status.busy": "2023-11-15T13:25:42.610208Z",
     "iopub.status.idle": "2023-11-15T13:25:43.524310Z",
     "shell.execute_reply": "2023-11-15T13:25:43.523256Z"
    },
    "papermill": {
     "duration": 0.926231,
     "end_time": "2023-11-15T13:25:43.526202",
     "exception": false,
     "start_time": "2023-11-15T13:25:42.599971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf98a26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.547484Z",
     "iopub.status.busy": "2023-11-15T13:25:43.546874Z",
     "iopub.status.idle": "2023-11-15T13:25:43.557765Z",
     "shell.execute_reply": "2023-11-15T13:25:43.556717Z"
    },
    "papermill": {
     "duration": 0.023728,
     "end_time": "2023-11-15T13:25:43.559794",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.536066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "aug_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.6),  \n",
    "    A.VerticalFlip(p=0.4), \n",
    "    A.GaussianBlur(blur_limit=3),   \n",
    "    A.RandomSnow(snow_point_lower=0.2, snow_point_upper=0.3, brightness_coeff=1.2, p=0.05), \n",
    "    A.RandomShadow(shadow_roi=(0.1, 0.2, 0.9, 0.9), p=0.15),  \n",
    "    A.RandomGamma (gamma_limit=(80, 120), p=0.25),  \n",
    "    A.RGBShift(p=0.25, r_shift_limit=15, g_shift_limit=15, b_shift_limit=15), \n",
    "    A.Cutout(p=0.3, max_h_size=25, max_w_size=25, fill_value=0),\n",
    "    A.RandomCrop(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603311db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.580013Z",
     "iopub.status.busy": "2023-11-15T13:25:43.579767Z",
     "iopub.status.idle": "2023-11-15T13:25:43.584120Z",
     "shell.execute_reply": "2023-11-15T13:25:43.583185Z"
    },
    "papermill": {
     "duration": 0.017334,
     "end_time": "2023-11-15T13:25:43.586786",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.569452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ori_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7aecfac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.607099Z",
     "iopub.status.busy": "2023-11-15T13:25:43.606863Z",
     "iopub.status.idle": "2023-11-15T13:25:43.612046Z",
     "shell.execute_reply": "2023-11-15T13:25:43.611282Z"
    },
    "papermill": {
     "duration": 0.01733,
     "end_time": "2023-11-15T13:25:43.613862",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.596532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a281b5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.634108Z",
     "iopub.status.busy": "2023-11-15T13:25:43.633835Z",
     "iopub.status.idle": "2023-11-15T13:25:43.641536Z",
     "shell.execute_reply": "2023-11-15T13:25:43.640724Z"
    },
    "papermill": {
     "duration": 0.019814,
     "end_time": "2023-11-15T13:25:43.643385",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.623571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "train_dataset_not_aug = ImageSegmentationDataset(images_folder= TRAIN_DIR,\n",
    "                             masks_folder= TRAIN_MASK_DIR,\n",
    "                             target_size= (256,256),\n",
    "                             augmentations = ori_transform)\n",
    "\n",
    "train_dataset_aug = ImageSegmentationDataset(images_folder= TRAIN_DIR,\n",
    "                             masks_folder= TRAIN_MASK_DIR,\n",
    "                             target_size= (256,256),\n",
    "                             augmentations = aug_transform)\n",
    "train_dataset = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0bd5e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.664087Z",
     "iopub.status.busy": "2023-11-15T13:25:43.663826Z",
     "iopub.status.idle": "2023-11-15T13:25:43.667578Z",
     "shell.execute_reply": "2023-11-15T13:25:43.666886Z"
    },
    "papermill": {
     "duration": 0.015917,
     "end_time": "2023-11-15T13:25:43.669397",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.653480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa824faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.689528Z",
     "iopub.status.busy": "2023-11-15T13:25:43.689269Z",
     "iopub.status.idle": "2023-11-15T13:25:43.694600Z",
     "shell.execute_reply": "2023-11-15T13:25:43.693811Z"
    },
    "papermill": {
     "duration": 0.017343,
     "end_time": "2023-11-15T13:25:43.696331",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.678988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e46367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:43.717568Z",
     "iopub.status.busy": "2023-11-15T13:25:43.717309Z",
     "iopub.status.idle": "2023-11-15T13:25:58.421836Z",
     "shell.execute_reply": "2023-11-15T13:25:58.420642Z"
    },
    "papermill": {
     "duration": 14.717157,
     "end_time": "2023-11-15T13:25:58.424159",
     "exception": false,
     "start_time": "2023-11-15T13:25:43.707002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.12)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.34.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "!wandb login 'e148ed8e0e7f84df32e1a5cd13e10de504c7be45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388ebf80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:25:58.446725Z",
     "iopub.status.busy": "2023-11-15T13:25:58.445865Z",
     "iopub.status.idle": "2023-11-15T13:26:30.169274Z",
     "shell.execute_reply": "2023-11-15T13:26:30.168007Z"
    },
    "papermill": {
     "duration": 31.738461,
     "end_time": "2023-11-15T13:26:30.172999",
     "exception": false,
     "start_time": "2023-11-15T13:25:58.434538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthanhtruongtran23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231115_132559-asq63zvn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-deluge-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/thanhtruongtran23/Unet_polyp-Segmentation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/thanhtruongtran23/Unet_polyp-Segmentation/runs/asq63zvn\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thanhtruongtran23/Unet_polyp-Segmentation/runs/asq63zvn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7dddf3e27d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project = 'Unet_polyp-Segmentation',\n",
    "    config = {\n",
    "        'learning_rate': 0.0001,\n",
    "        'architecture': 'ResUnet',\n",
    "        'dataset': 'Polyp',\n",
    "        'epoch': 50\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d757cb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:26:30.197021Z",
     "iopub.status.busy": "2023-11-15T13:26:30.196384Z",
     "iopub.status.idle": "2023-11-15T15:13:53.412802Z",
     "shell.execute_reply": "2023-11-15T15:13:53.411856Z"
    },
    "papermill": {
     "duration": 6443.2305,
     "end_time": "2023-11-15T15:13:53.414864",
     "exception": false,
     "start_time": "2023-11-15T13:26:30.184364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.3970630491\n",
      "Save model\n",
      "Epoch [2/50], Loss: 0.1621830199\n",
      "Save model\n",
      "Epoch [3/50], Loss: 0.1184547714\n",
      "Save model\n",
      "Epoch [4/50], Loss: 0.0920849170\n",
      "Save model\n",
      "Epoch [5/50], Loss: 0.0817161221\n",
      "Save model\n",
      "Epoch [6/50], Loss: 0.0724561898\n",
      "Save model\n",
      "Epoch [7/50], Loss: 0.0651862420\n",
      "Save model\n",
      "Epoch [8/50], Loss: 0.0597584515\n",
      "Save model\n",
      "Epoch [9/50], Loss: 0.0603968321\n",
      "Epoch [10/50], Loss: 0.0506495759\n",
      "Save model\n",
      "Epoch [11/50], Loss: 0.0469875398\n",
      "Save model\n",
      "Epoch [12/50], Loss: 0.0457227016\n",
      "Save model\n",
      "Epoch [13/50], Loss: 0.0444487441\n",
      "Save model\n",
      "Epoch [14/50], Loss: 0.0412673634\n",
      "Save model\n",
      "Epoch [15/50], Loss: 0.0416696289\n",
      "Epoch [16/50], Loss: 0.0405312688\n",
      "Save model\n",
      "Epoch [17/50], Loss: 0.0387094115\n",
      "Save model\n",
      "Epoch [18/50], Loss: 0.0359651122\n",
      "Save model\n",
      "Epoch [19/50], Loss: 0.0393700291\n",
      "Epoch [20/50], Loss: 0.0350619306\n",
      "Save model\n",
      "Epoch [21/50], Loss: 0.0355895909\n",
      "Epoch [22/50], Loss: 0.0342910846\n",
      "Save model\n",
      "Epoch [23/50], Loss: 0.0319241880\n",
      "Save model\n",
      "Epoch [24/50], Loss: 0.0294525836\n",
      "Save model\n",
      "Epoch [25/50], Loss: 0.0286927262\n",
      "Save model\n",
      "Epoch [26/50], Loss: 0.0300452345\n",
      "Epoch [27/50], Loss: 0.0259387484\n",
      "Save model\n",
      "Epoch [28/50], Loss: 0.0279674238\n",
      "Epoch [29/50], Loss: 0.0338653857\n",
      "Epoch [30/50], Loss: 0.0261542453\n",
      "Epoch [31/50], Loss: 0.0255031517\n",
      "Save model\n",
      "Epoch [32/50], Loss: 0.0246184889\n",
      "Save model\n",
      "Epoch [33/50], Loss: 0.0258547569\n",
      "Epoch [34/50], Loss: 0.0223486898\n",
      "Save model\n",
      "Epoch [35/50], Loss: 0.0244375528\n",
      "Epoch [36/50], Loss: 0.0198991335\n",
      "Save model\n",
      "Epoch [37/50], Loss: 0.0236403980\n",
      "Epoch [38/50], Loss: 0.0220467795\n",
      "Epoch [39/50], Loss: 0.0216397400\n",
      "Epoch [40/50], Loss: 0.0202187772\n",
      "Epoch [41/50], Loss: 0.0205588176\n",
      "Epoch [42/50], Loss: 0.0222300375\n",
      "Epoch [43/50], Loss: 0.0209553429\n",
      "Epoch [44/50], Loss: 0.0214895387\n",
      "Epoch [45/50], Loss: 0.0227211152\n",
      "Epoch [46/50], Loss: 0.0190424292\n",
      "Save model\n",
      "Epoch [47/50], Loss: 0.0186508648\n",
      "Save model\n",
      "Epoch [48/50], Loss: 0.0164980138\n",
      "Save model\n",
      "Epoch [49/50], Loss: 0.0185070110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0204699481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Loss 0.02047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgenial-deluge-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/thanhtruongtran23/Unet_polyp-Segmentation/runs/asq63zvn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231115_132559-asq63zvn/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "trainsize = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss_array = []\n",
    "best_loss = 100\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()  \n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    train_loss_array.append(epoch_loss)\n",
    "    wandb.log({'Loss': epoch_loss\n",
    "              })\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.10f}\")\n",
    "    \n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': epoch_loss\n",
    "        }\n",
    "        save_path = '/kaggle/working/submission.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        print('Save model')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5f7f72c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:13:53.451471Z",
     "iopub.status.busy": "2023-11-15T15:13:53.451169Z",
     "iopub.status.idle": "2023-11-15T15:13:53.984925Z",
     "shell.execute_reply": "2023-11-15T15:13:53.983713Z"
    },
    "papermill": {
     "duration": 0.554173,
     "end_time": "2023-11-15T15:13:53.986995",
     "exception": false,
     "start_time": "2023-11-15T15:13:53.432822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss from the checkpoint is: 0.0164980138\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/kaggle/working/submission.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) \n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# Sau khi nạp trạng thái, đưa cả model và optimizer lên device\n",
    "model.to(device)\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "loss_value = checkpoint['loss']\n",
    "\n",
    "print(f\"The loss from the checkpoint is: {loss_value:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5813fe2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:13:54.023836Z",
     "iopub.status.busy": "2023-11-15T15:13:54.023531Z",
     "iopub.status.idle": "2023-11-15T15:13:56.021334Z",
     "shell.execute_reply": "2023-11-15T15:13:56.019995Z"
    },
    "papermill": {
     "duration": 2.018575,
     "end_time": "2023-11-15T15:13:56.023729",
     "exception": false,
     "start_time": "2023-11-15T15:13:54.005154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir test_mask\n",
    "!mkdir test_overlapmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2b18cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:13:56.061689Z",
     "iopub.status.busy": "2023-11-15T15:13:56.061357Z",
     "iopub.status.idle": "2023-11-15T15:13:56.068352Z",
     "shell.execute_reply": "2023-11-15T15:13:56.067540Z"
    },
    "papermill": {
     "duration": 0.02763,
     "end_time": "2023-11-15T15:13:56.070285",
     "exception": false,
     "start_time": "2023-11-15T15:13:56.042655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_images_directory = \"/kaggle/input/bkai-igh-neopolyp/test/test\"\n",
    "output_masks_directory = \"test_mask/\"\n",
    "output_overlaps_directory = \"test_overlapmask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20696949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:13:56.105932Z",
     "iopub.status.busy": "2023-11-15T15:13:56.105666Z",
     "iopub.status.idle": "2023-11-15T15:14:32.082234Z",
     "shell.execute_reply": "2023-11-15T15:14:32.081042Z"
    },
    "papermill": {
     "duration": 35.996796,
     "end_time": "2023-11-15T15:14:32.084291",
     "exception": false,
     "start_time": "2023-11-15T15:13:56.087495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c695325ded465efde988dfb96d081533.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/26679bff55177a34fc01019eec999fd8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8cbdf366e057db382b8564872a27301a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d694539ef2424a9218697283baa3657e.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/be86f03d900fd197cd955fa095f97845.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/54ba59c7de13a35276a476420655433a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/ff55177a34fc01019eec999fd84e679b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7936140a2d5fc1443c4e445927738677.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6b83ef461c2a337948a41964c1d4f50a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6679bff55177a34fc01019eec999fd84.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c193ac8d551c149b60f2965341caf528.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/626650908b1cb932a767bf5487ced51b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/85a04faeeb2b535797395305af926a6f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/710d568df17586ad8f3297c819c90895.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/45b21960c94b0aab4c024a573c692195.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/318ecf467d7ad048df39beb176363408.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/66e057db382b8564872a27301a654864.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/df366e057db382b8564872a27301a654.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/80c643782707d7c359e27888daefee82.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5026b3550534bca540e24f489284b8e6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/782707d7c359e27888daefee82519763.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/936de314f2d95e6c487ffa651b477422.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/998906d3694abb47953b0e4909384b57.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/50534bca540e24f489284b8e6953ad88.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "Processed image: /kaggle/input/bkai-igh-neopolyp/test/test/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(test_images_directory):\n",
    "    image_path = os.path.join(test_images_directory, filename)\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_width = original_image.shape[0]\n",
    "    original_height = original_image.shape[1]\n",
    "    \n",
    "    resized_image = cv2.resize(original_image, (trainsize, trainsize))\n",
    "    transformed = ori_transform(image=resized_image)\n",
    "    model_input = transformed[\"image\"]\n",
    "    model_input = model_input.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_mask = model(model_input).squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    scaled_mask = cv2.resize(predicted_mask, (original_height, original_width))\n",
    "    class_mask = np.argmax(scaled_mask, axis=2)\n",
    "    colorized_mask = np.zeros((*class_mask.shape, 3)).astype(np.uint8)\n",
    "    \n",
    "    # Assuming mask_to_rgb is a predefined function that converts class masks to RGB images\n",
    "    rgb_colored_mask = mask_to_rgb(class_mask, color_dict)\n",
    "    rgb_colored_mask_corrected = cv2.cvtColor(rgb_colored_mask, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    combined_image = 0.7 * original_image + 0.3 * rgb_colored_mask_corrected\n",
    "    combined_image = combined_image.astype('uint8')\n",
    "    combined_image = cv2.cvtColor(combined_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    rgb_colored_mask = cv2.cvtColor(rgb_colored_mask, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(output_masks_directory, filename), rgb_colored_mask)\n",
    "    cv2.imwrite(os.path.join(output_overlaps_directory, filename), combined_image)\n",
    "    \n",
    "    print(\"Processed image:\", image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b70168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T15:14:32.136973Z",
     "iopub.status.busy": "2023-11-15T15:14:32.136360Z",
     "iopub.status.idle": "2023-11-15T15:14:35.021675Z",
     "shell.execute_reply": "2023-11-15T15:14:35.020606Z"
    },
    "papermill": {
     "duration": 2.913752,
     "end_time": "2023-11-15T15:14:35.023790",
     "exception": false,
     "start_time": "2023-11-15T15:14:32.110038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/test_mask/692195f853af7f8a4df1ec859759b7c8.jpeg\n",
      "/kaggle/working/test_mask/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n",
      "/kaggle/working/test_mask/d3694abb47953b0e4909384b57bb6a05.jpeg\n",
      "/kaggle/working/test_mask/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n",
      "/kaggle/working/test_mask/05b78a91391adc0bb223c4eaf3372eae.jpeg\n",
      "/kaggle/working/test_mask/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n",
      "/kaggle/working/test_mask/a9d45c3dbc695325ded465efde988dfb.jpeg\n",
      "/kaggle/working/test_mask/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n",
      "/kaggle/working/test_mask/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n",
      "/kaggle/working/test_mask/425b976973f13dd311a65d2b46d0a608.jpeg\n",
      "/kaggle/working/test_mask/e4a17af18f72c8e6166a915669c99390.jpeg\n",
      "/kaggle/working/test_mask/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n",
      "/kaggle/working/test_mask/e9082ea2c193ac8d551c149b60f29653.jpeg\n",
      "/kaggle/working/test_mask/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n",
      "/kaggle/working/test_mask/be86f03d900fd197cd955fa095f97845.jpeg\n",
      "/kaggle/working/test_mask/3dd311a65d2b46d0a6085835c525af63.jpeg\n",
      "/kaggle/working/test_mask/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n",
      "/kaggle/working/test_mask/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n",
      "/kaggle/working/test_mask/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n",
      "/kaggle/working/test_mask/cc5cfd263f1f90be28799235026b3550.jpeg\n",
      "/kaggle/working/test_mask/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n",
      "/kaggle/working/test_mask/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n",
      "/kaggle/working/test_mask/4baddc22268d4b4ef4d95ceea1195799.jpeg\n",
      "/kaggle/working/test_mask/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n",
      "/kaggle/working/test_mask/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n",
      "/kaggle/working/test_mask/c41545ba55aadaa77712a48e11d579d9.jpeg\n",
      "/kaggle/working/test_mask/e1797c77826f9a7021bab9fc73303988.jpeg\n",
      "/kaggle/working/test_mask/9c7976c1182df0de51d32128c358d1fd.jpeg\n",
      "/kaggle/working/test_mask/268d4b4ef4d95ceea11957998906d369.jpeg\n",
      "/kaggle/working/test_mask/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n",
      "/kaggle/working/test_mask/559c7e610b1531871f2fd85a04faeeb2.jpeg\n",
      "/kaggle/working/test_mask/87133b51209db6dcdda5cc8a788edaeb.jpeg\n",
      "/kaggle/working/test_mask/5026b3550534bca540e24f489284b8e6.jpeg\n",
      "/kaggle/working/test_mask/7936140a2d5fc1443c4e445927738677.jpeg\n",
      "/kaggle/working/test_mask/aeeb2b535797395305af926a6f23c5d6.jpeg\n",
      "/kaggle/working/test_mask/c4be73749a0d21db70dd094a7f32574d.jpeg\n",
      "/kaggle/working/test_mask/afe1f119f21b248d152b672ab3492fc6.jpeg\n",
      "/kaggle/working/test_mask/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n",
      "/kaggle/working/test_mask/285e26c90e1797c77826f9a7021bab9f.jpeg\n",
      "/kaggle/working/test_mask/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n",
      "/kaggle/working/test_mask/dd78294679c9cbb2a365b5574868eb60.jpeg\n",
      "/kaggle/working/test_mask/5b21960c94b0aab4c024a573c692195f.jpeg\n",
      "/kaggle/working/test_mask/5beb48f0be11d0309d1dff09b8405734.jpeg\n",
      "/kaggle/working/test_mask/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n",
      "/kaggle/working/test_mask/82ea2c193ac8d551c149b60f2965341c.jpeg\n",
      "/kaggle/working/test_mask/710d568df17586ad8f3297c819c90895.jpeg\n",
      "/kaggle/working/test_mask/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n",
      "/kaggle/working/test_mask/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n",
      "/kaggle/working/test_mask/6679bff55177a34fc01019eec999fd84.jpeg\n",
      "/kaggle/working/test_mask/d694539ef2424a9218697283baa3657e.jpeg\n",
      "/kaggle/working/test_mask/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n",
      "/kaggle/working/test_mask/d077bad31c8c5f54ffaa27a623511c38.jpeg\n",
      "/kaggle/working/test_mask/391adc0bb223c4eaf3372eae567c94ea.jpeg\n",
      "/kaggle/working/test_mask/ea42b4eebc9e5a87e443434ac60af150.jpeg\n",
      "/kaggle/working/test_mask/41ed86e58224cb76a67d4dcf9596154e.jpeg\n",
      "/kaggle/working/test_mask/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n",
      "/kaggle/working/test_mask/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n",
      "/kaggle/working/test_mask/fb905b78a91391adc0bb223c4eaf3372.jpeg\n",
      "/kaggle/working/test_mask/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n",
      "/kaggle/working/test_mask/626650908b1cb932a767bf5487ced51b.jpeg\n",
      "/kaggle/working/test_mask/39dda50f954ba59c7de13a35276a4764.jpeg\n",
      "/kaggle/working/test_mask/50534bca540e24f489284b8e6953ad88.jpeg\n",
      "/kaggle/working/test_mask/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n",
      "/kaggle/working/test_mask/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n",
      "/kaggle/working/test_mask/df366e057db382b8564872a27301a654.jpeg\n",
      "/kaggle/working/test_mask/c193ac8d551c149b60f2965341caf528.jpeg\n",
      "/kaggle/working/test_mask/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n",
      "/kaggle/working/test_mask/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n",
      "/kaggle/working/test_mask/f13dd311a65d2b46d0a6085835c525af.jpeg\n",
      "/kaggle/working/test_mask/fe1f119f21b248d152b672ab3492fc62.jpeg\n",
      "/kaggle/working/test_mask/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n",
      "/kaggle/working/test_mask/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n",
      "/kaggle/working/test_mask/2ed9fbb63b28163a745959c03983064a.jpeg\n",
      "/kaggle/working/test_mask/3c84417fda8019410b1fcf0625f608b4.jpeg\n",
      "/kaggle/working/test_mask/4417fda8019410b1fcf0625f608b4ce9.jpeg\n",
      "/kaggle/working/test_mask/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n",
      "/kaggle/working/test_mask/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n",
      "/kaggle/working/test_mask/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n",
      "/kaggle/working/test_mask/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n",
      "/kaggle/working/test_mask/e19769fa2d37d32780fd497e1c0e9082.jpeg\n",
      "/kaggle/working/test_mask/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n",
      "/kaggle/working/test_mask/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n",
      "/kaggle/working/test_mask/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n",
      "/kaggle/working/test_mask/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n",
      "/kaggle/working/test_mask/4ca6160127cd1d5ff99c267599fc487b.jpeg\n",
      "/kaggle/working/test_mask/318ecf467d7ad048df39beb176363408.jpeg\n",
      "/kaggle/working/test_mask/67d4dcf9596154efb7cef748d9cbd617.jpeg\n",
      "/kaggle/working/test_mask/6ad1468996b4a9ce6d840b53a6558038.jpeg\n",
      "/kaggle/working/test_mask/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n",
      "/kaggle/working/test_mask/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n",
      "/kaggle/working/test_mask/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n",
      "/kaggle/working/test_mask/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n",
      "/kaggle/working/test_mask/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n",
      "/kaggle/working/test_mask/782707d7c359e27888daefee82519763.jpeg\n",
      "/kaggle/working/test_mask/be4d18d5401f659532897255ce2dd4ae.jpeg\n",
      "/kaggle/working/test_mask/0a0317371a966bf4b3466463a3c64db1.jpeg\n",
      "/kaggle/working/test_mask/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n",
      "/kaggle/working/test_mask/7fda8019410b1fcf0625f608b4ce9762.jpeg\n",
      "/kaggle/working/test_mask/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n",
      "/kaggle/working/test_mask/c22268d4b4ef4d95ceea11957998906d.jpeg\n",
      "/kaggle/working/test_mask/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n",
      "/kaggle/working/test_mask/b21960c94b0aab4c024a573c692195f8.jpeg\n",
      "/kaggle/working/test_mask/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n",
      "/kaggle/working/test_mask/cf6644589e532a9ee954f81faedbce39.jpeg\n",
      "/kaggle/working/test_mask/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n",
      "/kaggle/working/test_mask/7af2ed9fbb63b28163a745959c039830.jpeg\n",
      "/kaggle/working/test_mask/ff55177a34fc01019eec999fd84e679b.jpeg\n",
      "/kaggle/working/test_mask/e3c84417fda8019410b1fcf0625f608b.jpeg\n",
      "/kaggle/working/test_mask/88e16d4ca6160127cd1d5ff99c267599.jpeg\n",
      "/kaggle/working/test_mask/63b8318ecf467d7ad048df39beb17636.jpeg\n",
      "/kaggle/working/test_mask/80cae6daedd989517cb8041ed86e5822.jpeg\n",
      "/kaggle/working/test_mask/c5a0808bee60b246359c68c836f843dc.jpeg\n",
      "/kaggle/working/test_mask/3425b976973f13dd311a65d2b46d0a60.jpeg\n",
      "/kaggle/working/test_mask/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n",
      "/kaggle/working/test_mask/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n",
      "/kaggle/working/test_mask/8fa8625605da2023387fd56c04414eaa.jpeg\n",
      "/kaggle/working/test_mask/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n",
      "/kaggle/working/test_mask/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n",
      "/kaggle/working/test_mask/8cbdf366e057db382b8564872a27301a.jpeg\n",
      "/kaggle/working/test_mask/dd094a7f32574d6c748c41743c6c08a1.jpeg\n",
      "/kaggle/working/test_mask/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n",
      "/kaggle/working/test_mask/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n",
      "/kaggle/working/test_mask/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n",
      "/kaggle/working/test_mask/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n",
      "/kaggle/working/test_mask/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n",
      "/kaggle/working/test_mask/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n",
      "/kaggle/working/test_mask/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n",
      "/kaggle/working/test_mask/6d3694abb47953b0e4909384b57bb6a0.jpeg\n",
      "/kaggle/working/test_mask/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n",
      "/kaggle/working/test_mask/b70dd094a7f32574d6c748c41743c6c0.jpeg\n",
      "/kaggle/working/test_mask/45b21960c94b0aab4c024a573c692195.jpeg\n",
      "/kaggle/working/test_mask/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n",
      "/kaggle/working/test_mask/3b8318ecf467d7ad048df39beb176363.jpeg\n",
      "/kaggle/working/test_mask/019410b1fcf0625f608b4ce97629ab55.jpeg\n",
      "/kaggle/working/test_mask/13dd311a65d2b46d0a6085835c525af6.jpeg\n",
      "/kaggle/working/test_mask/66e057db382b8564872a27301a654864.jpeg\n",
      "/kaggle/working/test_mask/85a04faeeb2b535797395305af926a6f.jpeg\n",
      "/kaggle/working/test_mask/1db239dda50f954ba59c7de13a35276a.jpeg\n",
      "/kaggle/working/test_mask/625559c7e610b1531871f2fd85a04fae.jpeg\n",
      "/kaggle/working/test_mask/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n",
      "/kaggle/working/test_mask/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n",
      "/kaggle/working/test_mask/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n",
      "/kaggle/working/test_mask/936de314f2d95e6c487ffa651b477422.jpeg\n",
      "/kaggle/working/test_mask/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n",
      "/kaggle/working/test_mask/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n",
      "/kaggle/working/test_mask/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n",
      "/kaggle/working/test_mask/80c643782707d7c359e27888daefee82.jpeg\n",
      "/kaggle/working/test_mask/54ba59c7de13a35276a476420655433a.jpeg\n",
      "/kaggle/working/test_mask/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n",
      "/kaggle/working/test_mask/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n",
      "/kaggle/working/test_mask/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n",
      "/kaggle/working/test_mask/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n",
      "/kaggle/working/test_mask/77e004e8bfb905b78a91391adc0bb223.jpeg\n",
      "/kaggle/working/test_mask/e73749a0d21db70dd094a7f32574d6c7.jpeg\n",
      "/kaggle/working/test_mask/cb1b387133b51209db6dcdda5cc8a788.jpeg\n",
      "/kaggle/working/test_mask/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n",
      "/kaggle/working/test_mask/26679bff55177a34fc01019eec999fd8.jpeg\n",
      "/kaggle/working/test_mask/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n",
      "/kaggle/working/test_mask/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n",
      "/kaggle/working/test_mask/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n",
      "/kaggle/working/test_mask/a51625559c7e610b1531871f2fd85a04.jpeg\n",
      "/kaggle/working/test_mask/998906d3694abb47953b0e4909384b57.jpeg\n",
      "/kaggle/working/test_mask/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n",
      "/kaggle/working/test_mask/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n",
      "/kaggle/working/test_mask/71f2fd85a04faeeb2b535797395305af.jpeg\n",
      "/kaggle/working/test_mask/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n",
      "/kaggle/working/test_mask/aafac813fe3ccba3e032dd2948a80c64.jpeg\n",
      "/kaggle/working/test_mask/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n",
      "/kaggle/working/test_mask/3c692195f853af7f8a4df1ec859759b7.jpeg\n",
      "/kaggle/working/test_mask/7f0019f7e6af7d7147763bdfb928d788.jpeg\n",
      "/kaggle/working/test_mask/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n",
      "/kaggle/working/test_mask/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n",
      "/kaggle/working/test_mask/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n",
      "/kaggle/working/test_mask/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n",
      "/kaggle/working/test_mask/68d4b4ef4d95ceea11957998906d3694.jpeg\n",
      "/kaggle/working/test_mask/c695325ded465efde988dfb96d081533.jpeg\n",
      "/kaggle/working/test_mask/60b246359c68c836f843dcf41f4dce3c.jpeg\n",
      "/kaggle/working/test_mask/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n",
      "/kaggle/working/test_mask/5a51625559c7e610b1531871f2fd85a0.jpeg\n",
      "/kaggle/working/test_mask/4f437f0019f7e6af7d7147763bdfb928.jpeg\n",
      "/kaggle/working/test_mask/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n",
      "/kaggle/working/test_mask/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n",
      "/kaggle/working/test_mask/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n",
      "/kaggle/working/test_mask/05734fbeedd0f9da760db74a29abdb04.jpeg\n",
      "/kaggle/working/test_mask/1531871f2fd85a04faeeb2b535797395.jpeg\n",
      "/kaggle/working/test_mask/3bbc04a3afe1f119f21b248d152b672a.jpeg\n",
      "/kaggle/working/test_mask/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n",
      "/kaggle/working/test_mask/461c2a337948a41964c1d4f50a5f3601.jpeg\n",
      "/kaggle/working/test_mask/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n",
      "/kaggle/working/test_mask/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n",
      "/kaggle/working/test_mask/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n",
      "/kaggle/working/test_mask/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n",
      "/kaggle/working/test_mask/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n",
      "/kaggle/working/test_mask/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n",
      "/kaggle/working/test_mask/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n",
      "/kaggle/working/test_mask/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n",
      "/kaggle/working/test_mask/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n",
      "/kaggle/working/test_mask/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n",
      "/kaggle/working/test_mask/4ef4d95ceea11957998906d3694abb47.jpeg\n",
      "/kaggle/working/test_mask/6b83ef461c2a337948a41964c1d4f50a.jpeg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    \n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    ## mask --> string\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/test_mask' # change this to the path to your output mask folder\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef4369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:38:36.975345Z",
     "iopub.status.busy": "2023-11-15T10:38:36.975041Z",
     "iopub.status.idle": "2023-11-15T10:38:36.995158Z",
     "shell.execute_reply": "2023-11-15T10:38:36.993845Z",
     "shell.execute_reply.started": "2023-11-15T10:38:36.975319Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-11-15T15:14:35.051922",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "killall5 -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb300f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4002717,
     "sourceId": 6967015,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-15T13:25:08.740847",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
